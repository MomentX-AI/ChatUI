# 對話上下文管理功能演示

## 🎯 功能概述

此聊天應用現在具備智能的對話上下文管理功能，能夠：

1. **自動追蹤對話歷史** - AI 能記住之前的對話內容
2. **智能管理記憶** - 當對話過長時自動優化上下文
3. **即時監控狀態** - 顯示記憶使用情況和管理狀態

## 🧪 測試步驟

### 1. 啟動應用
```bash
npm run dev
```
應用會在 http://localhost:3002 運行

### 2. 基本上下文測試

進行以下對話來測試 AI 是否記住上下文：

```
你: 我的名字是張三
AI: 你好張三！很高興認識你...

你: 我喜歡喝咖啡
AI: 好的，我記住了你喜歡喝咖啡...

你: 你還記得我的名字嗎？
AI: 當然記得，你是張三！

你: 我剛才說我喜歡什麼？
AI: 你說你喜歡喝咖啡。
```

### 3. 觀察上下文信息

在對話過程中，注意頂部的 **"🧠 對話記憶"** 面板：

- 點擊 `+` 號展開詳細信息
- 觀察 **訊息數量** 的變化
- 查看 **預估 Tokens** 的增長
- 注意 **記憶使用率** 進度條

### 4. 測試記憶管理

繼續進行長對話（發送 15+ 條訊息）來觸發記憶管理：

```
你: 請告訴我關於人工智能的歷史
AI: [長回答...]

你: 機器學習和深度學習有什麼區別？
AI: [長回答...]

... (繼續對話直到訊息數超過設定閾值)
```

當訊息數量超過閾值時，你會看到：
- 管理狀態變為 **"已啟用"** (黃色)
- 進度條顏色變為橘紅色
- 控制台出現上下文管理日誌

### 5. 測試摘要功能

在設定中確保：
- ✅ 啟用智能記憶管理
- ✅ 啟用對話摘要
- 最大訊息數量: 20
- 摘要觸發閾值: 15

繼續對話直到觸發摘要生成，觀察：
- 控制台出現 "Creating summary for X early messages"
- AI 會自動壓縮早期對話但保留關鍵信息

## 🔧 配置選項

在設定面板中可以調整：

### 基本設定
- **API 網址**: 本地 AI 服務地址
- **模型**: AI 模型名稱
- **溫度**: 回答隨機性 (0-1)
- **系統訊息**: AI 行為設定

### 對話記憶管理
- **啟用智能記憶管理**: 總開關
- **啟用對話摘要**: 摘要功能開關
- **最大訊息數量**: 觸發管理的訊息數 (5-50)
- **摘要觸發閾值**: 開始摘要的訊息數 (10-30)

## 🐛 除錯信息

開啟瀏覽器開發者工具的控制台，觀察這些日誌：

```
Context stats: { messageCount: X, estimatedTokens: Y, needsManagement: false, ... }
Managing context: X messages, threshold: Y
Creating summary for X early messages
Sending Y messages to API
Updated context stats: { ... }
```

## 📊 性能指標

- **Token 估算**: 每個字符約 0.25 tokens
- **管理閾值**: 預設 20 條訊息或 3000 tokens
- **摘要壓縮比**: 通常能將 10+ 條訊息壓縮為 1 條摘要
- **響應時間**: 摘要生成約需 2-5 秒

## ✅ 預期行為

1. **短對話** (< 20 訊息): 直接傳送所有歷史
2. **中等對話** (20-30 訊息): 使用滑動窗口保留最近訊息
3. **長對話** (> 30 訊息): 生成摘要 + 保留最近訊息
4. **錯誤處理**: 摘要失敗時降級使用滑動窗口

記住，這個系統讓 AI 能夠：
- 📚 記住對話歷史
- 🧠 理解上下文關聯
- ⚡ 自動優化性能
- 📊 透明顯示狀態 